#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è„šæœ¬ - éªŒè¯å¯¼å…¥çš„æ•°æ®
"""

import json
import re
from elasticsearch import Elasticsearch
from datetime import datetime

def test_es_connection():
    """æµ‹è¯•ESè¿æ¥"""
    try:
        es = Elasticsearch([{'host': 'localhost', 'port': 9200}])
        if es.ping():
            print("âœ“ ESè¿æ¥æ­£å¸¸")
            return es
        else:
            print("âœ— ESè¿æ¥å¤±è´¥")
            return None
    except Exception as e:
        print(f"âœ— ESè¿æ¥å¼‚å¸¸: {e}")
        return None

def get_indices_info(es):
    """è·å–ç´¢å¼•ä¿¡æ¯"""
    try:
        indices = es.cat.indices(format='json')
        print("\nğŸ“Š ç´¢å¼•ä¿¡æ¯:")
        for index in indices:
            if 'u2performance' in index['index']:
                print(f"  - ç´¢å¼•: {index['index']}")
                print(f"    æ–‡æ¡£æ•°: {index['docs.count']}")
                print(f"    å¤§å°: {index['store.size']}")
        return True
    except Exception as e:
        print(f"âœ— è·å–ç´¢å¼•ä¿¡æ¯å¤±è´¥: {e}")
        return False

def test_data_quality(es):
    """æµ‹è¯•æ•°æ®è´¨é‡"""
    try:
        # æœç´¢æ‰€æœ‰æ–‡æ¡£
        response = es.search(
            index="u2performance_for_test",
            body={
                "query": {"match_all": {}},
                "size": 10
            }
        )
        
        total_docs = response['hits']['total']['value']
        print(f"\nğŸ“ˆ æ•°æ®è´¨é‡æ£€æŸ¥:")
        print(f"  æ€»æ–‡æ¡£æ•°: {total_docs}")
        
        # æ£€æŸ¥å‡ ä¸ªæ ·æœ¬æ–‡æ¡£
        docs = response['hits']['hits']
        ip_pattern = re.compile(r'^(\d{1,3}\.){3}\d{1,3}$')
        
        valid_ips = 0
        valid_timestamps = 0
        valid_values = 0
        
        for doc in docs:
            source = doc['_source']
            
            # æ£€æŸ¥IPåœ°å€
            if 'hostip' in source and ip_pattern.match(str(source['hostip'])):
                valid_ips += 1
            
            # æ£€æŸ¥æ—¶é—´æˆ³
            if '@timestamp' in source:
                valid_timestamps += 1
            
            # æ£€æŸ¥æ•°å€¼å­—æ®µ
            if 'process_val' in source and isinstance(source['process_val'], (int, float)):
                valid_values += 1
        
        print(f"  æœ‰æ•ˆIPåœ°å€: {valid_ips}/{len(docs)}")
        print(f"  æœ‰æ•ˆæ—¶é—´æˆ³: {valid_timestamps}/{len(docs)}")
        print(f"  æœ‰æ•ˆæ•°å€¼: {valid_values}/{len(docs)}")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_search_functionality(es):
    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
    try:
        print(f"\nğŸ” æœç´¢åŠŸèƒ½æµ‹è¯•:")
        
        # æµ‹è¯•1: æŒ‰ä¸»æœºIPæœç´¢
        response = es.search(
            index="u2performance_for_test",
            body={
                "query": {
                    "term": {
                        "hostip": "10.1.60.62"
                    }
                },
                "size": 1
            }
        )
        print(f"  æŒ‰IPæœç´¢ç»“æœ: {response['hits']['total']['value']} æ¡")
        
        # æµ‹è¯•2: æŒ‰æ—¶é—´èŒƒå›´æœç´¢
        response = es.search(
            index="u2performance_for_test",
            body={
                "query": {
                    "range": {
                        "@timestamp": {
                            "gte": "2025-01-01T00:00:00.000Z",
                            "lte": "2025-12-31T23:59:59.999Z"
                        }
                    }
                },
                "size": 0
            }
        )
        print(f"  æŒ‰æ—¶é—´èŒƒå›´æœç´¢ç»“æœ: {response['hits']['total']['value']} æ¡")
        
        # æµ‹è¯•3: èšåˆæŸ¥è¯¢
        response = es.search(
            index="u2performance_for_test",
            body={
                "size": 0,
                "aggs": {
                    "vendors": {
                        "terms": {
                            "field": "vendor",
                            "size": 10
                        }
                    }
                }
            }
        )
        
        print(f"  å‚å•†åˆ†å¸ƒ:")
        for bucket in response['aggregations']['vendors']['buckets']:
            print(f"    {bucket['key']}: {bucket['doc_count']} æ¡")
        
        return True
        
    except Exception as e:
        print(f"âœ— æœç´¢åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_regex_validation():
    """æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼éªŒè¯"""
    print(f"\nğŸ§ª æ­£åˆ™è¡¨è¾¾å¼éªŒè¯æµ‹è¯•:")
    
    # æµ‹è¯•IPåœ°å€æ­£åˆ™
    ip_pattern = re.compile(r'^(\d{1,3}\.){3}\d{1,3}$')
    test_ips = ['10.1.60.62', '192.168.1.1', '256.1.1.1', 'invalid.ip']
    
    print("  IPåœ°å€éªŒè¯:")
    for ip in test_ips:
        valid = ip_pattern.match(ip) is not None
        status = "âœ“" if valid else "âœ—"
        print(f"    {status} {ip}: {'æœ‰æ•ˆ' if valid else 'æ— æ•ˆ'}")
    
    # æµ‹è¯•ä¸»æœºåæ¸…ç†
    hostname_pattern = re.compile(r'[^\w\-\.]')
    test_hostnames = ['F5GTM2800A4.HL-GZFW.CT.JXA', 'host@name', 'host<name>']
    
    print("  ä¸»æœºåæ¸…ç†:")
    for hostname in test_hostnames:
        cleaned = hostname_pattern.sub('_', hostname)
        print(f"    {hostname} â†’ {cleaned}")
    
    return True

def main():
    print("=" * 60)
    print("              Elasticsearch å¯¼å…¥æ•°æ®æµ‹è¯•")
    print("=" * 60)
    
    # è¿æ¥ES
    es = test_es_connection()
    if not es:
        return
    
    # è·å–ç´¢å¼•ä¿¡æ¯
    get_indices_info(es)
    
    # æµ‹è¯•æ•°æ®è´¨é‡
    test_data_quality(es)
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    test_search_functionality(es)
    
    # æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼
    test_regex_validation()
    
    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print("å¦‚æœæ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡ï¼Œè¯´æ˜æ•°æ®å¯¼å…¥æˆåŠŸä¸”è´¨é‡è‰¯å¥½ã€‚")

if __name__ == "__main__":
    main() 